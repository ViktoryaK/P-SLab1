---
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Name1 Surname1, Name2 Surname2, Name3 Surname3*

## Introduction

During the past three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;\
see [this
site](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)
for more detailed explanations.

## Data description

There are 5 datasets uploaded on the cms.

To determine your variant, take your team number from the list of teams
on cms and take *mod 5* - this is the number of your data set.

-   **0 - authors** This data set consists of citations of three famous
    writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP
    Lovecraft. The task with this data set is to classify a piece of
    text with the author who was more likely to write it.

-   **1 - discrimination** This data set consists of tweets that have
    discriminatory (sexism or racism) messages or of tweets that are of
    neutral mood. The task is to determine whether a given tweet has
    discriminatory mood or does not.

-   **2 - fake news** This data set contains data of American news: a
    headline and an abstract of the article. Each piece of news is
    classified as fake or credible. The task is to classify the news
    from test.csv as credible or fake.

-   **3 - sentiment** All the text messages contained in this data set
    are labeled with three sentiments: positive, neutral or negative.
    The task is to classify some text message as the one of positive
    mood, negative or neutral.

-   **4 - spam** This last data set contains SMS messages classified as
    spam or non-spam (ham in the data set). The task is to determine
    whether a given message is spam or non-spam.

Each data set consists of two files: *train.csv* and *test.csv*. The
first one you will need find the probabilities distributions for each of
the features, while the second one is needed for checking how well your
classifier works.

```{r}
# here goes a list of recommended libraries,
# though you may install other ones if they are needed
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
```

## Instructions

-   The first step is data pre-processing, which includes removing
    punctuation marks and stop words

-   represent each message as a bag-of-words

-   using the training set, calculate all the conditional probabilities
    in formula (1)

-   use those to predict classes for messages in the test set

-   evaluate effectiveness of the classifier by calculating the
    corresponding metrics

-   shortly summarize your work

-   do not forget to submit both the (compiled) Rmd source file and the
    .html output

### Data pre-processing

-   Read the *.csv* data files.
-   Ð¡lear your data from punctuation or other unneeded symbols.
-   Clear you data from stop words. You don't want words as is, and, or
    etc. to affect your probabilities distributions, so it is a wise
    decision to get rid of them. Find list of stop words in the cms
    under the lab task.
-   Represent each test message as its bag-of-words. Here:
    <https://machinelearningmastery.com/gentle-introduction-bag-words-model/>
    you can find general introduction to the bag-of-words model and
    examples on to create it.
-   It is highly recommended to get familiar with R dataframes, it would
    make the work much easier to do.
-   Useful links:
    -   <https://steviep42.github.io/webscraping/book/bagofwords.html#tidytext> -
        example of using *tidytext* to count frequencies of the words.
    -   Basics of Text Mining in R:
        <http://rstudio-pubs-static.s3.amazonaws.com/256588_57b585da6c054349825cba46685d8464.html>
        . Note that it also includes an example on how to create a bag
        of words from your text document.

```{r}
list.files(getwd())
list.files("data/3-sentiment")
```

```{r}
test_path <- "data/3-sentiment/test.csv"
train_path <- "data/3-sentiment/train.csv"

stop_words <- read_file("stop_words.txt")
# https://stackoverflow.com/questions/27195912/why-does-strsplit-return-a-list
splitted_stop_words <- strsplit(stop_words, split='\n')
splitted_stop_words <- splitted_stop_words[[1]]
stop_words = splitted_stop_words

```

```{r}
train <-  read.csv(file = train_path, stringsAsFactors = FALSE)
test <-  read.csv(file = test_path, stringsAsFactors = FALSE)
```

```{r}
# note the power functional features of R bring us! 
tidy_text <- unnest_tokens(train, 'splitted', 'text', token="words") %>%
             filter(!splitted %in% stop_words)

tidy_text
```

```{r}


tidy_text <- tidy_text %>%
mutate(
sentiment =  base::factor(tidy_text[,1], levels = c("negative", "neutral", "positive")) %>% as.numeric() %>% {. - 1}
  )

```

### Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!

```{r}

library(wordcloud)
library(tm)
#WORDCLOUDS
#positive <- subset(tidy_text,sentiment==2)
#wordcloud(positive$splitted, max.words = 50, colors = "blue")
#negative <- subset(tidy_text,sentiment==0)
#wordcloud(negative$splitted, max.words = 50, colors = "red")
#neutral <- subset(tidy_text,sentiment==1)
#wordcloud(neutral$splitted, max.words = 50, colors = "green")


```

## Classifier implementation

```{r}
naiveBayes <- setRefClass("naiveBayes",
                          
       # here it would be wise to have some vars to store intermediate result
       
       # frequency dict etc. Though pay attention to bag of words! 
       fields = list(
         
       ),
       methods = list(
                    fit = function()
                    {


                      
                      i=1
                      for (word in tidy_text$splitted) {
                      all = tidy_text %>% filter(splitted==word)
                      all = all %>% count(splitted==word)
                      all <- sum(all$n)
                      
               
                      
                      n = tidy_text %>% filter(splitted==word, sentiment=="0")
                      n = n %>% count(splitted==word)
                      n <- sum(n$n)
                      
    
                    
                      neu = tidy_text %>% filter(splitted==word, sentiment=="1")
                      neu = neu %>% count(splitted==word)
                      neu <- sum(neu$n)
                      
               
                      
                      p = tidy_text %>% filter(splitted==word, sentiment=="2")
                      p = p %>% count(splitted==word)
                      p <- sum(p$n)
                      
            
                    
                      n_prob = n / all
                      neu_prob = neu / all
                      p_prob = p / all
                    
                      env$n_n[i] <- n_prob
                      env$ne_ne[i] <- neu_prob
                      env$p_p[i] <- p_prob
                      env$words[i] <- word
                      
                      i <- i+1
                      }
                    },
                    
                    # return prediction for a single message 
                    predict = function(message)
                    {
                      
                      df = tidy_text %>% count(sentiment)
                      neg <- df$n[1] / (df$n[1] + df$n[2] + df$n[3])
                      neu <- df$n[2] / (df$n[1] + df$n[2] + df$n[3])
                      pos <- df$n[3] / (df$n[1] + df$n[2] + df$n[3])
                    
                      
                      mess <- data.frame(message)
                      
                      mess <- unnest_tokens(mess, "words", "message", token="words") %>% filter(!words %in% stop_words)
                      

                      
                     n_message = neg
                     neu_message = neu
                     p_message = pos
                     
                     for (word in mess$words) {
                      index <- match(word, env$words)
                       n_message <- n_message * env$n_n[index]
                       neu_message <- neu_message * match(word, env$ne_ne)
                       p_message <- p_message * match(word, env$p_p)
                     }
                     
                     print(n_message)
                     print(neu_message)
                     print(p_message)
                     
                    # return(max(n_message, neu_message, p_message))
                       
                       
                      
                      
                      
                    },

                    score = function(X_test, y_test)
                    {
                         # TODO
                    }
))

model = naiveBayes()

tidy_text$negative <- c(1:length(tidy_text[,2]))
         
tidy_text <- tidy_text %>% filter(negative<60)

env <- new.env()
env$n_n <- (1:length(tidy_text[,2]))
env$ne_ne <- (1:length(tidy_text[,2]))
env$p_p <- (1:length(tidy_text[,2]))
env$words <- (1:length(tidy_text[,2]))
env$indexes <- (1:length(tidy_text[,2]))

env$n_n[3]
model$fit()
#model$predict("For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .")
ls.str(env)

```



```{r}
#ls.str(env$n_n[3])
#model$predict("For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .")
match("gran", env$words)
match(1, env$n_n)

```
## Measure effectiveness of your classifier

-   Note that accuracy is not always a good metric for your classifier.
    Look at precision and recall curves, F1 score metric.
-   Visualize them.
-   Show failure cases.

## Conclusions

Summarize your work by explaining in a few sentences the points listed
below.

-   Describe the method implemented in general. Show what are
    mathematical foundations you are basing your solution on.
-   List pros and cons of the method. This should include the
    limitations of your method, all the assumption you make about the
    nature of your data etc.
